{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_qz1lu2l",
    "id": "665778BC4FD748188759D5FA0B4C36C8",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 梯度消失、梯度爆炸以及Kaggle房价预测\n",
    "\n",
    "1. 梯度消失和梯度爆炸\n",
    "2. 考虑到环境因素的其他问题\n",
    "3. Kaggle房价预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_eaw1lhq",
    "id": "2E84AE7BD5FD4456806865C6FBDBD0A0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 梯度消失和梯度爆炸\n",
    "\n",
    "深度模型有关数值稳定性的典型问题是消失（vanishing）和爆炸（explosion）。\n",
    "\n",
    "**当神经网络的层数较多时，模型的数值稳定性容易变差。**\n",
    "\n",
    "多层感知机的第$l$层的输出$\\boldsymbol{H}^{(l)} = \\boldsymbol{X} \\boldsymbol{W}^{(1)} \\boldsymbol{W}^{(2)} \\ldots \\boldsymbol{W}^{(l)}$。此时，如果层数$l$较大，$\\boldsymbol{H}^{(l)}$的计算可能会出现衰减或爆炸。举个例子，假设输入和所有层的权重参数都是标量，如权重参数为0.2和5，多层感知机的第30层输出为输入$\\boldsymbol{X}$分别与$0.2^{30} \\approx 1 \\times 10^{-21}$（消失）和$5^{30} \\approx 9 \\times 10^{20}$（爆炸）的乘积。当层数较多时，梯度的计算也容易出现消失或爆炸。\n",
    "\n",
    "# 随机初始化模型参数原因：值依然相等\n",
    "\n",
    "相同的话，输入计算的值相同反向梯度相同，迭代后相同，本质只有一个隐藏单元在发挥作用\n",
    "\n",
    "回顾多层感知机一节描述的多层感知机。为了方便解释，假设输出层只保留一个输出单元$o_1$（删去$o_2$和$o_3$以及指向它们的箭头），且隐藏层使用相同的激活函数。如果将每个隐藏单元的参数都初始化为相等的值，那么在正向传播时每个隐藏单元将根据相同的输入计算出相同的值，并传递至输出层。在反向传播中，每个隐藏单元的参数梯度值相等。因此，这些参数在使用基于梯度的优化算法迭代后值依然相等。之后的迭代也是如此。在这种情况下，无论隐藏单元有多少，隐藏层本质上只有1个隐藏单元在发挥作用。因此，正如在前面的实验中所做的那样，我们通常将神经网络的模型参数，特别是权重参数，进行随机初始化。\n",
    "\n",
    "\n",
    "\n",
    "###  PyTorch的默认随机初始化\n",
    "\n",
    "随机初始化模型参数的方法有很多。在线性回归的简洁实现中，我们使用`torch.nn.init.normal_()`使模型`net`的权重参数采用正态分布的随机初始化方式。不过，PyTorch中`nn.Module`的模块参数都采取了较为合理的初始化策略（不同类型的layer具体采样的哪一种初始化方法的可参考[源代码](https://github.com/pytorch/pytorch/tree/master/torch/nn/modules)），因此一般不用我们考虑。\n",
    "\n",
    "\n",
    "### Xavier随机初始化\n",
    "\n",
    "还有一种比较常用的随机初始化方法叫作Xavier随机初始化。\n",
    "假设某全连接层的输入个数为$a$，输出个数为$b$，Xavier随机初始化将使该层中权重参数的每个元素都随机采样于均匀分布\n",
    "\n",
    "\n",
    "$$\n",
    "U\\left(-\\sqrt{\\frac{6}{a+b}}, \\sqrt{\\frac{6}{a+b}}\\right).\n",
    "$$\n",
    "\n",
    "\n",
    "它的设计主要考虑到，模型参数初始化后，每层输出的方差不该受该层输入个数影响，且每层梯度的方差也不该受该层输出个数影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_yrhfrka",
    "id": "A39077A2F4E2417588D16EDFB59C9324",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 考虑环境因素\n",
    "\n",
    "## 协变量偏移\n",
    "\n",
    "这里我们假设，虽然输入的分布可能随时间而改变，但是标记函数，即条件分布P（y∣x）不会改变。虽然这个问题容易理解，但在实践中也容易忽视。\n",
    "\n",
    "比如区分猫和狗的一个例子。我们的训练数据使用的是猫和狗的真实的照片，但是在测试时，我们被要求对猫和狗的卡通图片进行分类。显然，这不太可能奏效，问题的根源在于特征分布的变化（即协变量的变化），。数学上，我们可以说P（x）改变了，但P（y∣x）保持不变。尽管它的有用性并不局限于此，当我们认为x导致y时，协变量移位通常是正确的假设。\n",
    "\n",
    "\n",
    "## 标签偏移\n",
    "\n",
    "标签偏移可以简单理解为测试时出现了训练时没有的标签\n",
    "\n",
    "## 概念偏移\n",
    "简单术语的定义也会发生相当大的概念转变。如果我们要建立一个机器翻译系统，分布P（y∣x）可能因我们的位置而异。这个问题很难发现。另一个可取之处是P（y∣x）通常只是逐渐变化。\n",
    "\n",
    "如果数据量足够的情况下，确保训练数据集和测试集中的数据取自同一个数据集，可以防止协变量偏移和标签偏移是正确的。如果数据量很少，少到测试集中存在训练集中未包含的标签，就会发生标签偏移。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_xnnkt44",
    "id": "6EDBE35E1A98479895A1681A62688B81",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Kaggle 房价预测实战\n",
    "\n",
    "作为深度学习基础篇章的总结，我们将对本章内容学以致用。下面，让我们动手实战一个Kaggle比赛：房价预测。本节将提供未经调优的数据的预处理、模型的设计和超参数的选择。我们希望读者通过动手操作、仔细观察实验现象、认真分析实验结果并不断调整方法，得到令自己满意的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": false,
    "graffitiCellId": "id_rppdqvv",
    "id": "4B7D88B7F9D5401988D5CFAEAEE4D60D",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/home/kesci/input/houseprices2807/house-prices-advanced-regression-techniques/test.csv\")\n",
    "train_data = pd.read_csv(\"/home/kesci/input/houseprices2807/house-prices-advanced-regression-techniques/train.csv\")\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:])) #去掉id和 价格\n",
    "\n",
    "#预处理\n",
    "#1数据类型标准化，# 标准化后，每个数值特征的均值变为0，所以可以直接用0来替换缺失值\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 标准化后，每个数值特征的均值变为0，所以可以直接用0来替换缺失值\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "\n",
    "# 2one_hot:dummy_na=True将缺失值也当作合法的特征值并为其创建指示特征\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "graffitiCellId": "id_wnd1cmy",
    "id": "6010D2628BF648D8B9C852A881CF99E0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float)\n",
    "train_labels = torch.tensor(train_data.SalePrice.values, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_6bdgzdo",
    "id": "C8FE8AB28E8A4F329C501F299DDC0F24",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_9g14lrp",
    "id": "0C80D529E2BE4F9FBADB12DDE1840DAD",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "下面定义比赛用来评价模型的对数均方根误差。给定预测值$\\hat y_1, \\ldots, \\hat y_n$和对应的真实标签$y_1,\\ldots, y_n$，它的定义为\n",
    "\n",
    "\n",
    "$$\n",
    "\\sqrt{\\frac{1}{n}\\sum_{i=1}^n\\left(\\log(y_i)-\\log(\\hat y_i)\\right)^2}.\n",
    "$$\n",
    "\n",
    "\n",
    "对数均方根误差的实现如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "graffitiCellId": "id_qjz6u65",
    "id": "387CB5F1C97A4A1F8943165FA3C0BE11",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "def log_rmse(net, features, labels):\n",
    "    with torch.no_grad():\n",
    "        # 将小于1的值设成1，使得取对数时数值更稳定\n",
    "        clipped_preds = torch.max(net(features), torch.tensor(1.0))\n",
    "        rmse = torch.sqrt(2 * loss(clipped_preds.log(), labels.log()).mean())\n",
    "    return rmse.item()\n",
    "\n",
    "def get_net(feature_num):\n",
    "    net = nn.Linear(feature_num, 1)\n",
    "    for param in net.parameters():\n",
    "        nn.init.normal_(param, mean=0, std=0.01)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_b27rtld",
    "id": "565F294EF5FF4277ABC474EBF9C1C4BC",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "下面的训练函数跟本章中前几节的不同在于使用了Adam优化算法。相对之前使用的小批量随机梯度下降，它对学习率相对不那么敏感。我们将在之后的“优化算法”一章里详细介绍它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "graffitiCellId": "id_erbtdm9",
    "id": "DDC3C34CDD804C048FA12AFA5A5812A5",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []\n",
    "    dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "    train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "    # 这里使用了Adam优化算法\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "    net = net.float()\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            l = loss(net(X.float()), y.float())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
    "    return train_ls, test_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_nlimv5e",
    "id": "B7830AF406C249718ED109BF413578C0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## K折交叉验证\n",
    "我们在模型选择、欠拟合和过拟合中介绍了$K$折交叉验证。它将被用来选择模型设计并调节超参数。下面实现了一个函数，它返回第`i`折交叉验证时所需要的训练和验证数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "graffitiCellId": "id_mrp7nyy",
    "id": "2D7D3C06E1D24E238F0DA935CD81B0B8",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat((X_train, X_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_2xl2r2q",
    "id": "66D0CEC41DE34F2B8399E5034CA64824",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "在$K$折交叉验证中我们训练$K$次并返回训练和验证的平均误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "graffitiCellId": "id_83qykff",
    "id": "B8FDE10586B445E28ABA5E786A6B6509",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def k_fold(k, X_train, y_train, num_epochs,\n",
    "           learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net(X_train.shape[1])\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
    "                                   weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        if i == 0:\n",
    "            d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
    "                         range(1, num_epochs + 1), valid_ls,\n",
    "                         ['train', 'valid'])\n",
    "        print('fold %d, train rmse %f, valid rmse %f' % (i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_trewijv",
    "id": "3EB022DC108048A892CB21203A633877",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 模型选择\n",
    "我们使用一组未经调优的超参数并计算交叉验证误差。可以改动这些超参数来尽可能减小平均测试误差。\n",
    "有时候你会发现一组参数的训练误差可以达到很低，但是在$K$折交叉验证上的误差可能反而较高。这种现象很可能是由过拟合造成的。因此，当训练误差降低时，我们要观察$K$折交叉验证上的误差是否也相应降低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "graffitiCellId": "id_tlka7i5",
    "id": "989B1E6DC2F046A6899429AC97B29EC0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, train rmse 0.241365, valid rmse 0.223083\n",
      "fold 1, train rmse 0.229118, valid rmse 0.267488\n",
      "fold 2, train rmse 0.232072, valid rmse 0.237995\n",
      "fold 3, train rmse 0.238050, valid rmse 0.218671\n",
      "fold 4, train rmse 0.231004, valid rmse 0.259185\n",
      "5-fold validation: avg train rmse 0.234322, avg valid rmse 0.241284\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/989B1E6DC2F046A6899429AC97B29EC0/q5jfhgk0ux.svg\">"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "print('%d-fold validation: avg train rmse %f, avg valid rmse %f' % (k, train_l, valid_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_3h0djuc",
    "id": "CC30DD4229814CF78FC9960656E38450",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 预测并在Kaggle中提交结果\n",
    "下面定义预测函数。在预测之前，我们会使用完整的训练数据集来重新训练模型，并将预测结果存成提交所需要的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "graffitiCellId": "id_bfeohke",
    "id": "6439054A3497425386D81BAF6A0E5914",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "                   num_epochs, lr, weight_decay, batch_size):\n",
    "    net = get_net(train_features.shape[1])\n",
    "    train_ls, _ = train(net, train_features, train_labels, None, None,\n",
    "                        num_epochs, lr, weight_decay, batch_size)\n",
    "    d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse')\n",
    "    print('train rmse %f' % train_ls[-1])\n",
    "    preds = net(test_features).detach().numpy()\n",
    "    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n",
    "    submission.to_csv('./submission.csv', index=False)\n",
    "    # sample_submission_data = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_488x0hf",
    "id": "2CD0AF62C0B942B88E759B35E9A1C010",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "设计好模型并调好超参数之后，下一步就是对测试数据集上的房屋样本做价格预测。如果我们得到与交叉验证时差不多的训练误差，那么这个结果很可能是理想的，可以在Kaggle上提交结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_y9xgm83",
    "id": "9F99F864AB2946B6A6AD66AADBD44F2D",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
